第一：业务解耦

第二：最终一致性

跨jvm的数据一致性 解决方案 有两个：
1, 强一致性  --- 分布式事物  太难  落地成本高
2, 最终一致性 --- 通过记录 和 补偿的机制 进行处理  消息
                 做所有不确定事情之前 先把事情记录下来，然后去做不确定的事 结果通常分三种：
                 a) 成功 -- 可以把我们记录的东西 清理掉
                 b) 失败
                 c) 不确定 (超时 等等)
                 对于失败 和 不确定 我们可以通过定时任务的方式 将这些事情再做一遍 直到成功为止。
                 局部逻辑 可以维护到一个本地事物中。
                 会出现消息重复的问题 这个就需要做好消息幂等的操作。
                 kafka消息队列 在设计的层面 就会存在丢消息的可能。

第三： 广播
      我们只关心我们的消息是否发送到消息队列 对于订阅方 它只需要去消费消息即可 我们不用考虑消费方的事情。

第四： 错峰与流控
      前段在接受用户请求 使用lvs 加机器 Nginx 就可以搞定的。
      但是数据库的处理 是十分的有限 即使使用ssd 和 分库分表的技术 单机的处理能力 依旧有限
      从成本的考虑 我们不能奢望数据库的机器不限多
      系统和系统之前 网关这块 的处理量  跟前段的并发流 也不是在一个数量级的
      (对于强一致性 和 时效性很高的系统 rpc是优于消息队列的)

 常见
 RabbitMQ
 Kafka

 Kafka:
 高性能，跨语言，分布式，发布订阅消息系统
 快速持久化
 高吞吐 10万/s
 hadoop 数据并行加载 kafka是一个很好的选择方案  在线 和 离线处理

 kafka集群 包含一个或者多个服务 每个服务器 就是一个broker
           每条发布到kafka集群的消息 都有一个类别 这个类别 我们成为topic
           物理上不同topic的消息 是分开存储的
           一个topic的消息 虽然保存在不同的broker上 但用户只需指定消息的topic就可以生产和消费数据，而不用关心
           数据存储在哪个broker上面。
           partition:是物理上的概念 每个topic包含一个或者多个partition
           producer:是负责发布消息到kafka的broker里面
           Consumer:是消息的消费者 负责从kafka的broker中读取消息的客户端
           Consumer Group: 每个consumer都属于固定的Consumer Group
           我们可以为每个consumer指定其consumer name, 如果不指定就属于默认的group
           partition的算法可以指定的
           (kafka的启动时依赖zookeeper的)
RabbitMQ
        producer将消息发送给exchange
        exchange将消息发送给queue 可以一对多 可以一对一 (RoutingKey定义这个关系)
        consumer从queue中获取消息进行消费
        它有自己的管理界面 这点非常牛逼。



